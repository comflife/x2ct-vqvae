#!/usr/bin/env python3
"""
UltraLiDAR ëª¨ë¸ê³¼ Transformer ì°¨ì› í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import os
import sys
sys.path.append('/home/byounggun/r2l/x2ct-vqvae')

from utils.simple_ultralidar_wrapper import load_simple_ultralidar_model
from ml_collections import config_flags
from absl import app, flags
import ml_collections

# ì„¤ì • ë¡œë“œ
FLAGS = flags.FLAGS
config_flags.DEFINE_config_file("config", "configs/radar_to_lidar_sampler_config.py", "Main config")
config_flags.DEFINE_config_file("radar_config", "configs/default_radar_vqgan_config.py", "Radar config")  
config_flags.DEFINE_config_file("lidar_config", "configs/default_lidar_vqgan_config.py", "Lidar config")

def test_ultralidar_dimensions():
    """UltraLiDAR ëª¨ë¸ì˜ ì‹¤ì œ ì°¨ì› í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("TESTING ULTRALIDAR MODEL DIMENSIONS")
    print("=" * 60)
    
    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # UltraLiDAR ëª¨ë¸ ë¡œë“œ
    radar_path = "/home/byounggun/r2l/UltraLiDAR_nusc_waymo/work_dirs/nusc_radar_debug/epoch_121.pth"
    lidar_path = "/home/byounggun/r2l/UltraLiDAR_nusc_waymo/work_dirs/nusc_stage2/epoch_200.pth"
    
    print(f"\n1. Loading UltraLiDAR models...")
    ae_radar = load_simple_ultralidar_model(radar_path, 'radar').to(device)
    ae_lidar = load_simple_ultralidar_model(lidar_path, 'lidar').to(device)
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± (640x640 BEV)
    print(f"\n2. Testing with 640x640 BEV input...")
    dummy_bev = torch.randn(1, 1, 640, 640).to(device)
    print(f"Input BEV shape: {dummy_bev.shape}")
    
    # Radar ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
    print(f"\n3. Testing Radar encoding...")
    with torch.no_grad():
        radar_latents = ae_radar.encoder(dummy_bev)
        print(f"Radar latents shape: {radar_latents.shape}")
        
        radar_quant, radar_vq_loss, radar_info = ae_radar.quantize(radar_latents)
        print(f"Radar quantized shape: {radar_quant.shape}")
        
        # ì˜¬ë°”ë¥¸ reshape: (B, C, H, W) -> (B, H*W, C)
        B, C, H, W = radar_quant.shape
        radar_context_correct = radar_quant.permute(0, 2, 3, 1).contiguous().view(B, H*W, C)
        print(f"Radar context (CORRECT): {radar_context_correct.shape} = (batch, seq_len, emb_dim)")
        print(f"  Sequence length: {H*W}, Embedding dim: {C}")
        
        # ì˜ëª»ëœ ë°©ì‹ (ê¸°ì¡´ ì½”ë“œì˜ ë¬¸ì œ)
        radar_context_wrong = radar_quant.view(B, -1, radar_quant.shape[-1])
        print(f"Radar context (WRONG): {radar_context_wrong.shape} = (batch, seq_len, emb_dim)")
        print(f"  This would give wrong sequence length and embedding dim!")
        
    # Lidar ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
    print(f"\n4. Testing Lidar encoding...")
    with torch.no_grad():
        lidar_latents = ae_lidar.encoder(dummy_bev)
        print(f"Lidar latents shape: {lidar_latents.shape}")
        
        lidar_quant, lidar_vq_loss, lidar_info = ae_lidar.quantize(lidar_latents)
        print(f"Lidar quantized shape: {lidar_quant.shape}")
        
        if isinstance(lidar_info, dict) and 'min_encoding_indices' in lidar_info:
            lidar_codes = lidar_info['min_encoding_indices']
            print(f"Lidar codes shape: {lidar_codes.shape}")
            print(f"Lidar codes flattened: {lidar_codes.view(1, -1).shape}")
        else:
            print(f"Lidar info type: {type(lidar_info)}")
            if isinstance(lidar_info, dict):
                print(f"Lidar info keys: {list(lidar_info.keys())}")
    
    # ì„ë² ë”© ê°€ì¤‘ì¹˜ í™•ì¸
    print(f"\n5. Testing embedding weights...")
    if hasattr(ae_lidar, 'get_embedding_weight'):
        embedding_weight = ae_lidar.get_embedding_weight()
        print(f"Lidar embedding weight shape: {embedding_weight.shape}")
    else:
        print("No get_embedding_weight method found")
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ ê³„ì‚° (ì˜¬ë°”ë¥¸ ë°©ì‹)
    print(f"\n6. Calculating sequence lengths (CORRECTED)...")
    B, C, H, W = radar_quant.shape
    radar_seq_len_correct = H * W  # 80 * 80 = 6400
    radar_emb_dim = C  # 1024
    
    if isinstance(lidar_info, dict) and 'min_encoding_indices' in lidar_info:
        lidar_seq_len = lidar_codes.view(1, -1).shape[1]  # 6400
        total_seq_len_correct = radar_seq_len_correct + lidar_seq_len
        print(f"Radar context sequence length: {radar_seq_len_correct}")
        print(f"Radar embedding dimension: {radar_emb_dim}")
        print(f"Lidar target sequence length: {lidar_seq_len}")
        print(f"Total sequence length: {total_seq_len_correct}")
        print(f"")
        print(f"Block size limit: 16384")
        if total_seq_len_correct <= 16384:
            print(f"âœ… Total sequence length is within block size!")
        else:
            print(f"âŒ Total sequence length exceeds block size by {total_seq_len_correct - 16384}")
    
    # ê¸°ì¡´ ì˜ëª»ëœ ê³„ì‚°ë„ ë³´ì—¬ì£¼ê¸°
    print(f"\n6b. Previous WRONG calculation:")
    radar_seq_len_wrong = radar_quant.view(1, -1, radar_quant.shape[-1]).shape[1]
    total_seq_len_wrong = radar_seq_len_wrong + lidar_seq_len if 'lidar_seq_len' in locals() else radar_seq_len_wrong
    print(f"Wrong radar sequence length: {radar_seq_len_wrong}")
    print(f"Wrong total sequence length: {total_seq_len_wrong}")
    
    print(f"\n7. Memory usage:")
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        print(f"GPU memory allocated: {allocated:.2f} GB")

def test_transformer_config():
    """Transformer ì„¤ì • í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("TESTING TRANSFORMER CONFIGURATION")
    print("=" * 60)
    
    H = FLAGS.config
    # ConfigëŠ” lockedì´ë¯€ë¡œ ì§ì ‘ í• ë‹¹í•˜ì§€ ì•Šê³  FLAGSì—ì„œ ê°€ì ¸ì˜¤ê¸°
    radar_config = FLAGS.radar_config
    lidar_config = FLAGS.lidar_config
    
    print(f"\nMain config:")
    print(f"  Block size: {H.model.block_size}")
    print(f"  Embedding dim: {H.model.n_emb}")
    print(f"  Attention heads: {H.model.n_head}")
    print(f"  Layers: {H.model.n_layers}")
    
    print(f"\nRadar config:")
    print(f"  Codebook size: {radar_config.model.codebook_size}")
    print(f"  Embedding dim: {radar_config.model.emb_dim}")
    print(f"  Latent shape: {radar_config.model.latent_shape}")
    
    print(f"\nLidar config:")
    print(f"  Codebook size: {lidar_config.model.codebook_size}")
    print(f"  Embedding dim: {lidar_config.model.emb_dim}")
    print(f"  Latent shape: {lidar_config.model.latent_shape}")
    
    return H, radar_config, lidar_config

def test_context_dimension_compatibility():
    """Context ì°¨ì› í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("TESTING CONTEXT DIMENSION COMPATIBILITY")
    print("=" * 60)
    
    H = FLAGS.config
    radar_config = FLAGS.radar_config
    lidar_config = FLAGS.lidar_config
    
    # Transformer context linear layer ì˜ˆìƒ ì…ë ¥ ì°¨ì›
    expected_context_dim = lidar_config.model.emb_dim  # ct_configëŠ” lidar_configë¡œ ëŒ€ì²´ë¨
    transformer_emb_dim = H.model.n_emb
    
    print(f"Expected context input dim (from lidar config): {expected_context_dim}")
    print(f"Transformer embedding dim: {transformer_emb_dim}")
    print(f"Block size limit: {H.model.block_size}")
    
    # ì‹¤ì œ UltraLiDARì—ì„œ ë‚˜ì˜¤ëŠ” ì°¨ì›ê³¼ ë¹„êµ
    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')
    radar_path = "/home/byounggun/r2l/UltraLiDAR_nusc_waymo/work_dirs/nusc_radar_debug/epoch_121.pth"
    
    ae_radar = load_simple_ultralidar_model(radar_path, 'radar').to(device)
    dummy_bev = torch.randn(1, 1, 640, 640).to(device)
    
    with torch.no_grad():
        radar_latents = ae_radar.encoder(dummy_bev)
        radar_quant, _, _ = ae_radar.quantize(radar_latents)
        
        # ì˜¬ë°”ë¥¸ reshape: (B, C, H, W) -> (B, H*W, C)
        B, C, H, W = radar_quant.shape
        radar_context = radar_quant.permute(0, 2, 3, 1).contiguous().view(B, H*W, C)
        
        print(f"\nActual radar context shape: {radar_context.shape}")
        print(f"Actual radar embedding dim: {radar_context.shape[-1]}")
        print(f"Actual radar sequence length: {radar_context.shape[1]}")
        
        # í˜¸í™˜ì„± í™•ì¸
        if radar_context.shape[-1] == expected_context_dim:
            print("âœ… Context dimension MATCHES config!")
        else:
            print(f"âŒ Context dimension MISMATCH! Got {radar_context.shape[-1]}, expected {expected_context_dim}")
            
        if radar_context.shape[1] <= H.model.block_size//2:  # context + targetë¥¼ ê³ ë ¤
            print("âœ… Sequence length within reasonable block size!")
        else:
            print(f"âŒ Sequence length may be too large! Got {radar_context.shape[1]}, half of block size is {H.model.block_size//2}")
            
        return radar_context.shape

def main(argv):
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("Starting UltraLiDAR dimension compatibility tests...")
    
    try:
        test_ultralidar_dimensions()
        H, radar_config, lidar_config = test_transformer_config() 
        context_shape = test_context_dimension_compatibility()
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ SUMMARY AND RECOMMENDATIONS")
        print("=" * 60)
        
        print(f"âœ… UltraLiDAR models load successfully")
        print(f"âœ… Embedding dimensions match (1024)")
        print(f"âœ… Sequence lengths are manageable:")
        print(f"   - Radar context: 6,400 tokens")  
        print(f"   - Lidar target: 6,400 tokens")
        print(f"   - Total: 12,800 tokens (within block_size 16,384)")
        
        print(f"\nğŸ”§ FIXES NEEDED:")
        print(f"1. Fix reshape in generate_latent_ids(): use permute(0,2,3,1).view() instead of view()")
        print(f"2. Make sure transformer context_linear expects 1024 input dimensions")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ALL TESTS COMPLETED!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    app.run(main)
